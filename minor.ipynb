{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msite\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_site\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "#importing the stock price of infosys of year 2023 from 2 jan to 29 dec\n",
    "\n",
    "\n",
    "data = pd.read_csv('INFY_DATA.csv')\n",
    "fd = pd.read_csv('INFY_DATA.csv')\n",
    "\n",
    "st.title('Stock price prediction')\n",
    "st.write(data.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the MA(Moving Average) 100, it will work for the 101 row it will find the mean of the first 100 closing stock data\n",
    "#for the first 100 days no MA\n",
    "#for 101 it will find mean of previous 100 days closing price\n",
    "#it is a stock analysis tool used by stock market analysts to figure out if MA200>MA100, then the stock goes uptrend\n",
    "ma100 = data.Close.rolling(100).mean()\n",
    "\n",
    "#find the MA(Moving Average) 200, it will work for the 201 row it will find the mean of the first 200 closing stock data\n",
    "ma200 = data.Close.rolling(200).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZATIONS\n",
    "\n",
    "st.subheader('Closing Price vs Time chart with 100MV and 200MV')\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.plot(data.Close)\n",
    "plt.plot(ma100,'r')\n",
    "plt.plot(ma200,'g')\n",
    "plt.plot(data.Close)\n",
    "st.pyplot(plt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['Close'].values.reshape(-1, 1)\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_normalized = scaler.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_size = int(len(data_normalized) * 0.8)\n",
    "test_size = len(data_normalized) - train_size\n",
    "train_data, test_data = data_normalized[0:train_size, :], data_normalized[train_size:len(data_normalized), :]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create dataset with look back\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i + look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "\n",
    "    #now convert x_train,y_train in numpy array for LSTM model    \n",
    "    return np.array(X), np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with look back\n",
    "look_back = 100\n",
    "X_train, Y_train = create_dataset(train_data, look_back)\n",
    "X_test, Y_test = create_dataset(test_data, look_back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create dataset with look back\n",
    "look_back = 100\n",
    "X_train, Y_train = create_dataset(train_data, look_back)\n",
    "X_test, Y_test = create_dataset(test_data, look_back)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "select = st.selectbox('Choose your algorithm',['Depth Gated','Peephole','Vanilla','KNN'])\n",
    "if select=='Depth Gated':\n",
    "    model_dglstm = Sequential()\n",
    "    model_dglstm.add(LSTM(50, return_sequences=True, input_shape=(1, look_back), implementation=2))  # Depth Gated LSTM\n",
    "    model_dglstm.add(LSTM(50))\n",
    "    model_dglstm.add(Dense(1))\n",
    "    model_dglstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_dglstm.fit(X_train, Y_train, epochs=25, batch_size=1, verbose=2)\n",
    "    train_predict_dglstm = model_dglstm.predict(X_train)\n",
    "    test_predict_dglstm = model_dglstm.predict(X_test)\n",
    "    train_predict_dglstm = scaler.inverse_transform(train_predict_dglstm)\n",
    "    test_predict_dglstm = scaler.inverse_transform(test_predict_dglstm)\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.plot(data, label='Actual')\n",
    "    plt.plot(np.concatenate([train_predict_dglstm, test_predict_dglstm]), label='Depth Gated LSTM Predictions')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    st.pyplot(plt)\n",
    "elif select=='Peephole':\n",
    "    # Define and compile Peephole LSTM model\n",
    "    model_plstm = Sequential()\n",
    "    model_plstm.add(LSTM(50, return_sequences=True, input_shape=(1, look_back), implementation=1))  # Peephole LSTM\n",
    "    model_plstm.add(LSTM(50))\n",
    "    model_plstm.add(Dense(1))\n",
    "    model_plstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_plstm.fit(X_train, Y_train, epochs=25, batch_size=1, verbose=2)\n",
    "    train_predict_plstm = model_plstm.predict(X_train)\n",
    "    test_predict_plstm = model_plstm.predict(X_test)\n",
    "    train_predict_plstm = scaler.inverse_transform(train_predict_plstm)\n",
    "    test_predict_plstm = scaler.inverse_transform(test_predict_plstm)\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.plot(data, label='Actual')\n",
    "    plt.plot(np.concatenate([train_predict_plstm, test_predict_plstm]), label='Vanilla LSTM Predictions')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    st.pyplot(plt)\n",
    "elif select=='Vanilla':\n",
    "    # Define and compile Vanilla LSTM model\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(50, input_shape=(1, look_back)))  # Vanilla LSTM\n",
    "    model_lstm.add(Dense(1))\n",
    "    model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_lstm.fit(X_train, Y_train, epochs=25, batch_size=1, verbose=2)\n",
    "    train_predict_lstm = model_lstm.predict(X_train)\n",
    "    test_predict_lstm = model_lstm.predict(X_test)\n",
    "    train_predict_lstm = scaler.inverse_transform(train_predict_lstm)\n",
    "    test_predict_lstm = scaler.inverse_transform(test_predict_lstm)\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.plot(data, label='Actual')\n",
    "    plt.plot(np.concatenate([train_predict_lstm, test_predict_lstm]), label='Vanilla LSTM Predictions')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    st.pyplot(plt)\n",
    "else:\n",
    "    #input features to predict whether customer should buy or sell\n",
    "    #classification problem,whether I should buy or sell the stock\n",
    "    fd['Open - Close'] = fd['Open'] - fd['Close']\n",
    "    fd['High - Low'] = fd['High'] - fd['Low']\n",
    "    X = fd['Open - Close','High - Low']\n",
    "    #X.head(5)\n",
    "    Y = np.where(fd['Close'].shift(-1)>fd['Close'],1,-1)\n",
    "    #if i purchase a stock today for 500,i have historical data \n",
    "    #if next day it is 600, then it is +1,else -1\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.25,random_state = 44)\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn import neighbors\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    #optimal value of k\n",
    "    #to do that we use gridsearchcv, k -> hyperparamter\n",
    "    params = {'n_neighbors':[2,3,4,5,6,7,8,9,10,11,12,13,14,15]}\n",
    "    knn = neighbors.KNeighborsClassifier()\n",
    "    model = GridSearchCV(knn,params,cv=5)\n",
    "    model.fit(x_train,y_train)\n",
    "    accuracy_train = accuracy_score(y_train,model.predict(x_train))\n",
    "    accuracy_test = accuracy_score(y_test,model.predict(x_test))\n",
    "    #print(accuracy_train,accuracy_test,sep=' ')\n",
    "    st.write('ACCURACY TRAIN')\n",
    "    st.write(accuracy_train)\n",
    "    st.write('ACCURACY TEST')\n",
    "    st.write(accuracy_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
